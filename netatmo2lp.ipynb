{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3686f22-9202-4455-a1e3-f0f1453f2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script converts Netatmo CSV files to Line Protocol\n",
    "#\n",
    "# Line protocol yyntax is \n",
    "# <measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b2bcb66-4533-4a45-9516-8ea335845fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file example\n",
    "#  Name;Long;Lat;ModuleName;ModuleType\n",
    "#  \"Living room\";26.004168;44.452849;Outdoor;Outdoor\n",
    "#  Timestamp;\"Timezone : Europe/Bucharest\";Temperature;Humidity\n",
    "#  1467814227;\"2016/07/06 17:10:27\";29.5;56\n",
    "#  1467814485;\"2016/07/06 17:14:45\";29.7;42\n",
    "#  1467814791;\"2016/07/06 17:19:51\";29.4;40\n",
    "#\n",
    "# Corresponding Line protocol\n",
    "#  Rosu,lat=44.452849,long=26.004168,ModuleType=Outdoor,Timezone=Europe/Bucharest Temperature=29.5,Humidity=56 1467814227\n",
    "#  Rosu,lat=44.452849,long=26.004168,ModuleType=Outdoor,Timezone=Europe/Bucharest Temperature=29.7,Humidity=42 1467814485\n",
    "#  Rosu,lat=44.452849,long=26.004168,ModuleType=Outdoor,Timezone=Europe/Bucharest Temperature=29.4,Humidity=40 1467814791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a59aca-5a8d-4011-a6e9-3d821179e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24e5ed9a-fcaf-4e83-97ed-73f445ce5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The field \"Measurement\" is initialized as the name of the village I live in, which is in the suburban area of Bucharest, Romania\n",
    "# This has to be specified by the user, as this information in not availlable in the CSV files\n",
    "# CSV files list only the name I gave to the base station, in muy case \"Living room\"\n",
    "measurement = \"Rosu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9216c938-c6e3-4c2c-bed5-8f72f8bba534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a row to InfluxDB line protocol\n",
    "def to_influxdb_line_protocol(row, measurement, tags):\n",
    "    # This line extracts the timestamp from the row dictionary. It assumes that the row contains a key named 'Timestamp'\n",
    "    timestamp = row['Timestamp']\n",
    "    # This line constructs the field set for the InfluxDB line protocol. \n",
    "    # It extracts the Temperature and Humidity values from the row dictionary and formats them into a string.\n",
    "    # f\"Temperature={row['Temperature']},Humidity={row['Humidity']}\": This is an f-string (formatted string literal) that embeds the values of Temperature and Humidity into the string.\n",
    "    fields = f\"Temperature={row['Temperature']},Humidity={row['Humidity']}\"\n",
    "    # This line constructs the tag set for the InfluxDB line protocol.\n",
    "    # tags.items(): This returns a view object that displays a list of a dictionary's key-value tuple pairs.\n",
    "    # [f\"{key}={value}\" for key, value in tags.items()]: This is a list comprehension that iterates over the key-value pairs in the tags dictionary and formats each pair as key=value.\n",
    "    # \",\".join(...): This joins the list of formatted tag strings into a single string, with each pair separated by a comma\n",
    "    tag_set = \",\".join([f\"{key}={value}\" for key, value in tags.items()])\n",
    "    # This line combines the measurement name, tag set, field set, and timestamp into the InfluxDB line protocol format.\n",
    "    # f\"{measurement},{tag_set} {fields} {timestamp}\": This is another f-string that formats the final line protocol string \n",
    "    # with the measurement, tag set, fields, and timestamp separated by appropriate delimiters.\n",
    "    return f\"{measurement},{tag_set} {fields} {timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f12ecd-1c00-4239-b2b1-8737c4863565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['debug_2024.csv', 'Outdoor_6_24_2024(7).csv', 'Outdoor_6_24_2024(30).csv', 'Outdoor_6_24_2024(24).csv', 'Outdoor_6_24_2024(4).csv', 'Outdoor_6_24_2024(19).csv', 'lp_2016_10.csv', 'lp_2020_07.csv', 'lp_2018_07.csv', 'Outdoor_6_24_2024(12).csv', 'Outdoor_6_24_2024(22).csv', 'Outdoor_6_24_2024(14).csv', 'Outdoor_6_24_2024(21).csv', 'Outdoor_6_24_2024(2).csv', 'lp_2022_01.csv', 'Outdoor_6_24_2024(28).csv', 'Outdoor_6_24_2024(15).csv', 'lp_2017_04.csv', 'lp_2023_01.csv', 'lp_2017_10.csv', 'Outdoor_6_24_2024(25).csv', 'Outdoor_6_24_2024(26).csv', 'lp_2020_04.csv', 'lp_2018_04.csv', 'Outdoor_6_24_2024(16).csv', 'lp_2017_07.csv', 'Outdoor_6_24_2024(10).csv', 'lp_2019_04.csv', 'lp_2018_01.csv', 'Outdoor_6_24_2024(5).csv', 'lp_2023_10.csv', 'Outdoor_6_24_2024(20).csv', 'lp_2023_04.csv', 'Outdoor_6_24_2024(1).csv', 'lp_2021_10.csv', 'Outdoor_6_24_2024(3).csv', 'lp_2020_10.csv', 'lp_2024_01.csv', 'Outdoor_6_24_2024(31).csv', 'lp_2024_06.csv', 'lp_2019_10.csv', 'Outdoor_6_24_2024.csv', 'lp_2016_07.csv', 'debug_min.csv', 'lp_2019_07.csv', 'Outdoor_6_24_2024(6).csv', 'lp_2022_07.csv', 'lp_2017_01.csv', 'debug_reference.csv', 'lp_2021_04.csv', 'lp_2019_01.csv', 'Outdoor_6_24_2024(27).csv', 'Outdoor_6_24_2024(13).csv', 'lp_2022_04.csv', 'lp_2023_07.csv', 'Outdoor_6_24_2024(11).csv', 'lp_2018_10.csv', 'lp_2020_01.csv', 'Outdoor_6_24_2024(17).csv', 'Outdoor_6_24_2024(29).csv', 'Outdoor_6_24_2024(23).csv', 'lp_2022_10.csv', 'Outdoor_6_24_2024(8).csv', 'lp_2024_04.csv', 'lp_2021_07.csv', 'lp_2021_01.csv', 'Outdoor_6_24_2024(9).csv', 'debug_max.csv', 'Outdoor_June_2024.csv', 'Outdoor_6_24_2024(18).csv']\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files in the current directory\n",
    "# The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell. It is useful for searching for files with specific patterns in their names.\n",
    "# glob.glob(\"*.csv\"): This function call searches for all files in the current directory that have a .csv extension. The \"*.csv\" is a pattern where * matches any number of characters. T\n",
    "# csv_files: This variable will be a list containing the filenames of all the .csv files found in the current directory\n",
    "csv_files = glob.glob(\"*.csv\")\n",
    "# This line prints the list of .csv files found. If no .csv files are found, it will print an empty list []\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c0e40b4-d814-4200-a8be-a6d3533318a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File debug_2024.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(7).csv\n",
      "First timestamp: 1522530223\n",
      "First date (UTC): 2018-03-31 21:03:43+00:00\n",
      "First date (Local): 2018-04-01 00:03:43+03:00\n",
      "Year and month: 2018_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2018_04.lp\n",
      "File: Outdoor_6_24_2024(30).csv\n",
      "First timestamp: 1704060279\n",
      "First date (UTC): 2023-12-31 22:04:39+00:00\n",
      "First date (Local): 2024-01-01 00:04:39+02:00\n",
      "Year and month: 2024_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2024_01.lp\n",
      "File: Outdoor_6_24_2024(24).csv\n",
      "First timestamp: 1656623010\n",
      "First date (UTC): 2022-06-30 21:03:30+00:00\n",
      "First date (Local): 2022-07-01 00:03:30+03:00\n",
      "Year and month: 2022_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2022_07.lp\n",
      "File: Outdoor_6_24_2024(4).csv\n",
      "First timestamp: 1498856608\n",
      "First date (UTC): 2017-06-30 21:03:28+00:00\n",
      "First date (Local): 2017-07-01 00:03:28+03:00\n",
      "Year and month: 2017_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2017_07.lp\n",
      "File: Outdoor_6_24_2024(19).csv\n",
      "First timestamp: 1617224466\n",
      "First date (UTC): 2021-03-31 21:01:06+00:00\n",
      "First date (Local): 2021-04-01 00:01:06+03:00\n",
      "Year and month: 2021_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2021_04.lp\n",
      "File lp_2016_10.csv does not have the required header. Skipping.\n",
      "File lp_2020_07.csv does not have the required header. Skipping.\n",
      "File lp_2018_07.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(12).csv\n",
      "First timestamp: 1561928443\n",
      "First date (UTC): 2019-06-30 21:00:43+00:00\n",
      "First date (Local): 2019-07-01 00:00:43+03:00\n",
      "Year and month: 2019_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2019_07.lp\n",
      "File: Outdoor_6_24_2024(22).csv\n",
      "First timestamp: 1640988029\n",
      "First date (UTC): 2021-12-31 22:00:29+00:00\n",
      "First date (Local): 2022-01-01 00:00:29+02:00\n",
      "Year and month: 2022_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2022_01.lp\n",
      "File: Outdoor_6_24_2024(14).csv\n",
      "First timestamp: 1577829904\n",
      "First date (UTC): 2019-12-31 22:05:04+00:00\n",
      "First date (Local): 2020-01-01 00:05:04+02:00\n",
      "Year and month: 2020_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2020_01.lp\n",
      "File: Outdoor_6_24_2024(21).csv\n",
      "First timestamp: 1633035886\n",
      "First date (UTC): 2021-09-30 21:04:46+00:00\n",
      "First date (Local): 2021-10-01 00:04:46+03:00\n",
      "Year and month: 2021_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2021_10.lp\n",
      "File: Outdoor_6_24_2024(2).csv\n",
      "First timestamp: 1483221618\n",
      "First date (UTC): 2016-12-31 22:00:18+00:00\n",
      "First date (Local): 2017-01-01 00:00:18+02:00\n",
      "Year and month: 2017_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2017_01.lp\n",
      "File lp_2022_01.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(28).csv\n",
      "First timestamp: 1688158928\n",
      "First date (UTC): 2023-06-30 21:02:08+00:00\n",
      "First date (Local): 2023-07-01 00:02:08+03:00\n",
      "Year and month: 2023_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2023_07.lp\n",
      "File: Outdoor_6_24_2024(15).csv\n",
      "First timestamp: 1585688524\n",
      "First date (UTC): 2020-03-31 21:02:04+00:00\n",
      "First date (Local): 2020-04-01 00:02:04+03:00\n",
      "Year and month: 2020_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2020_04.lp\n",
      "File lp_2017_04.csv does not have the required header. Skipping.\n",
      "File lp_2023_01.csv does not have the required header. Skipping.\n",
      "File lp_2017_10.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(25).csv\n",
      "First timestamp: 1664571828\n",
      "First date (UTC): 2022-09-30 21:03:48+00:00\n",
      "First date (Local): 2022-10-01 00:03:48+03:00\n",
      "Year and month: 2022_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2022_10.lp\n",
      "File: Outdoor_6_24_2024(26).csv\n",
      "First timestamp: 1672524148\n",
      "First date (UTC): 2022-12-31 22:02:28+00:00\n",
      "First date (Local): 2023-01-01 00:02:28+02:00\n",
      "Year and month: 2023_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2023_01.lp\n",
      "File lp_2020_04.csv does not have the required header. Skipping.\n",
      "File lp_2018_04.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(16).csv\n",
      "First timestamp: 1593554828\n",
      "First date (UTC): 2020-06-30 22:07:08+00:00\n",
      "First date (Local): 2020-07-01 01:07:08+03:00\n",
      "Year and month: 2020_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2020_07.lp\n",
      "File lp_2017_07.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(10).csv\n",
      "First timestamp: 1546293874\n",
      "First date (UTC): 2018-12-31 22:04:34+00:00\n",
      "First date (Local): 2019-01-01 00:04:34+02:00\n",
      "Year and month: 2019_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2019_01.lp\n",
      "File lp_2019_04.csv does not have the required header. Skipping.\n",
      "File lp_2018_01.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(5).csv\n",
      "First timestamp: 1506805258\n",
      "First date (UTC): 2017-09-30 21:00:58+00:00\n",
      "First date (Local): 2017-10-01 00:00:58+03:00\n",
      "Year and month: 2017_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2017_10.lp\n",
      "File lp_2023_10.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(20).csv\n",
      "First timestamp: 1625087043\n",
      "First date (UTC): 2021-06-30 21:04:03+00:00\n",
      "First date (Local): 2021-07-01 00:04:03+03:00\n",
      "Year and month: 2021_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2021_07.lp\n",
      "File lp_2023_04.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(1).csv\n",
      "First timestamp: 1475269235\n",
      "First date (UTC): 2016-09-30 21:00:35+00:00\n",
      "First date (Local): 2016-10-01 00:00:35+03:00\n",
      "Year and month: 2016_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2016_10.lp\n",
      "File lp_2021_10.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(3).csv\n",
      "First timestamp: 1490994202\n",
      "First date (UTC): 2017-03-31 21:03:22+00:00\n",
      "First date (Local): 2017-04-01 00:03:22+03:00\n",
      "Year and month: 2017_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2017_04.lp\n",
      "File lp_2020_10.csv does not have the required header. Skipping.\n",
      "File lp_2024_01.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(31).csv\n",
      "First timestamp: 1711918971\n",
      "First date (UTC): 2024-03-31 21:02:51+00:00\n",
      "First date (Local): 2024-04-01 00:02:51+03:00\n",
      "Year and month: 2024_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2024_04.lp\n",
      "File lp_2024_06.csv does not have the required header. Skipping.\n",
      "File lp_2019_10.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024.csv\n",
      "First timestamp: 1467814227\n",
      "First date (UTC): 2016-07-06 14:10:27+00:00\n",
      "First date (Local): 2016-07-06 17:10:27+03:00\n",
      "Year and month: 2016_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2016_07.lp\n",
      "File lp_2016_07.csv does not have the required header. Skipping.\n",
      "File debug_min.csv does not have the required header. Skipping.\n",
      "File lp_2019_07.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(6).csv\n",
      "First timestamp: 1514757831\n",
      "First date (UTC): 2017-12-31 22:03:51+00:00\n",
      "First date (Local): 2018-01-01 00:03:51+02:00\n",
      "Year and month: 2018_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2018_01.lp\n",
      "File lp_2022_07.csv does not have the required header. Skipping.\n",
      "File lp_2017_01.csv does not have the required header. Skipping.\n",
      "File debug_reference.csv does not have the required header. Skipping.\n",
      "File lp_2021_04.csv does not have the required header. Skipping.\n",
      "File lp_2019_01.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(27).csv\n",
      "First timestamp: 1680296624\n",
      "First date (UTC): 2023-03-31 21:03:44+00:00\n",
      "First date (Local): 2023-04-01 00:03:44+03:00\n",
      "Year and month: 2023_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2023_04.lp\n",
      "File: Outdoor_6_24_2024(13).csv\n",
      "First timestamp: 1569877448\n",
      "First date (UTC): 2019-09-30 21:04:08+00:00\n",
      "First date (Local): 2019-10-01 00:04:08+03:00\n",
      "Year and month: 2019_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2019_10.lp\n",
      "File lp_2022_04.csv does not have the required header. Skipping.\n",
      "File lp_2023_07.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(11).csv\n",
      "First timestamp: 1554066156\n",
      "First date (UTC): 2019-03-31 21:02:36+00:00\n",
      "First date (Local): 2019-04-01 00:02:36+03:00\n",
      "Year and month: 2019_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2019_04.lp\n",
      "File lp_2018_10.csv does not have the required header. Skipping.\n",
      "File lp_2020_01.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(17).csv\n",
      "First timestamp: 1601499709\n",
      "First date (UTC): 2020-09-30 21:01:49+00:00\n",
      "First date (Local): 2020-10-01 00:01:49+03:00\n",
      "Year and month: 2020_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2020_10.lp\n",
      "File: Outdoor_6_24_2024(29).csv\n",
      "First timestamp: 1696107667\n",
      "First date (UTC): 2023-09-30 21:01:07+00:00\n",
      "First date (Local): 2023-10-01 00:01:07+03:00\n",
      "Year and month: 2023_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2023_10.lp\n",
      "File: Outdoor_6_24_2024(23).csv\n",
      "First timestamp: 1648760681\n",
      "First date (UTC): 2022-03-31 21:04:41+00:00\n",
      "First date (Local): 2022-04-01 00:04:41+03:00\n",
      "Year and month: 2022_04\n",
      "InfluxDB line protocol data has been saved to Rosu_2022_04.lp\n",
      "File lp_2022_10.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(8).csv\n",
      "First timestamp: 1530392456\n",
      "First date (UTC): 2018-06-30 21:00:56+00:00\n",
      "First date (Local): 2018-07-01 00:00:56+03:00\n",
      "Year and month: 2018_07\n",
      "InfluxDB line protocol data has been saved to Rosu_2018_07.lp\n",
      "File lp_2024_04.csv does not have the required header. Skipping.\n",
      "File lp_2021_07.csv does not have the required header. Skipping.\n",
      "File lp_2021_01.csv does not have the required header. Skipping.\n",
      "File: Outdoor_6_24_2024(9).csv\n",
      "First timestamp: 1538341215\n",
      "First date (UTC): 2018-09-30 21:00:15+00:00\n",
      "First date (Local): 2018-10-01 00:00:15+03:00\n",
      "Year and month: 2018_10\n",
      "InfluxDB line protocol data has been saved to Rosu_2018_10.lp\n",
      "File debug_max.csv does not have the required header. Skipping.\n",
      "File: Outdoor_June_2024.csv\n",
      "First timestamp: 1717189436\n",
      "First date (UTC): 2024-05-31 21:03:56+00:00\n",
      "First date (Local): 2024-06-01 00:03:56+03:00\n",
      "Year and month: 2024_06\n",
      "InfluxDB line protocol data has been saved to Rosu_2024_06.lp\n",
      "File: Outdoor_6_24_2024(18).csv\n",
      "First timestamp: 1609452113\n",
      "First date (UTC): 2020-12-31 22:01:53+00:00\n",
      "First date (Local): 2021-01-01 00:01:53+02:00\n",
      "Year and month: 2021_01\n",
      "InfluxDB line protocol data has been saved to Rosu_2021_01.lp\n"
     ]
    }
   ],
   "source": [
    "# Process CSV Files\n",
    "for input_file in csv_files:\n",
    "    with open(input_file, 'r') as file:\n",
    "        first_line = file.readline().strip()\n",
    "\n",
    "    # Check if the first line contains the required header\n",
    "    if first_line != \"Name;Long;Lat;ModuleName;ModuleType\":\n",
    "        print(f\"File {input_file} does not have the required header. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Read the metadata (first two rows)\n",
    "    metadata = pd.read_csv(input_file, sep=';', nrows=2)\n",
    "\n",
    "    # Metadata example (rows 0:1)\n",
    "    # Name;Long;Lat;ModuleName;ModuleType\n",
    "    # \"Living room\";26.004168;44.452849;Outdoor;Outdoor\n",
    "\n",
    "    # Remove double quotes from metadata columns\n",
    "    for col in metadata.columns:\n",
    "        if metadata[col].dtype == 'object':\n",
    "            metadata[col] = metadata[col].map(lambda x: x.strip('\"') if isinstance(x, str) else x)\n",
    "\n",
    "    # Extract latitude, longitude, ModuleType, and Timezone from metadata\n",
    "    lat = metadata['Lat'][0]\n",
    "    long = metadata['Long'][0]\n",
    "    module_type = metadata['ModuleType'][0]\n",
    "\n",
    "    # Data example (rows 2:...)\n",
    "    # Timestamp;\"Timezone : Europe/Bucharest\";Temperature;Humidity\n",
    "    # 1467814227;\"2016/07/06 17:10:27\";29.5;56\n",
    "\n",
    "    # Timezone is in the second row, second column\n",
    "    # metadata.iloc[1, 1]: This accesses the element in the second row and second column of the DataFrame. Indexing in pandas starts from 0, so 1 refers to the second row and second column.\n",
    "    # .split(':')[1]: This splits the string at the colon (:) and selects the second part (index 1). Assuming the string is formatted as \"key: timezone\", this will extract the timezone part.\n",
    "    timezone_str = metadata.iloc[1, 1].split(':')[1].strip()\n",
    "    # The purpose of this line of code is to convert a string representation of a timezone into a pytz timezone object. This object can then be used for timezone-aware date and time operations.\n",
    "    timezone = pytz.timezone(timezone_str)\n",
    "\n",
    "    # Read the time-series data starting from the correct row\n",
    "    time_series_data = pd.read_csv(input_file, sep=';', skiprows=2)\n",
    "\n",
    "    # Remove double quotes from time-series data columns\n",
    "    for col in time_series_data.columns:\n",
    "        if time_series_data[col].dtype == 'object':\n",
    "            time_series_data[col] = time_series_data[col].map(lambda x: x.strip('\"') if isinstance(x, str) else x)\n",
    "\n",
    "    # Strip any leading/trailing spaces from column names\n",
    "    time_series_data.columns = time_series_data.columns.str.strip()\n",
    "\n",
    "    # Extract the date from the first measurement\n",
    "    # This will be used for output file naming\n",
    "    # Is needed because Unix timestamps are UTC\n",
    "    # and I want the files to be named according to the local time\n",
    "    first_timestamp = int(time_series_data['Timestamp'].iloc[0])\n",
    "    first_date_utc = datetime.utcfromtimestamp(first_timestamp).replace(tzinfo=pytz.utc)\n",
    "    first_date_local = first_date_utc.astimezone(timezone)\n",
    "    year_month = first_date_local.strftime('%Y_%m')  # Format to \"YYYY_MM\"\n",
    "\n",
    "    # Print debug information\n",
    "    print(f\"File: {input_file}\")\n",
    "    print(f\"First timestamp: {first_timestamp}\")\n",
    "    print(f\"First date (UTC): {first_date_utc}\")\n",
    "    print(f\"First date (Local): {first_date_local}\")\n",
    "    print(f\"Year and month: {year_month}\")\n",
    "\n",
    "    # Convert time-series data to InfluxDB line protocol\n",
    "    tags = {\"lat\": lat, \"long\": long, \"ModuleType\": module_type, \"Timezone\": timezone_str}\n",
    "\n",
    "    lines = time_series_data.apply(lambda row: to_influxdb_line_protocol(row, measurement, tags), axis=1)\n",
    "\n",
    "    # Create new filename based on the date of the first measurement\n",
    "    output_file = f\"{measurement}_{year_month}.lp\"\n",
    "\n",
    "    # Save the result to a new CSV file without quotes\n",
    "    with open(output_file, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "    print(f\"InfluxDB line protocol data has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9bca0-5b37-4220-9b75-b510c2b06c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c40e2-df9d-47fc-a7b8-3b314d8426c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
